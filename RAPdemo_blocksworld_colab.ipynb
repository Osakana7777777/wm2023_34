{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiYHuHEyGm0u",
        "outputId": "82846d28-8c1b-4f7a-83ae-c7f29bad5e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan  7 05:56:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b tutorial https://github.com/Ber666/llm-reasoners.git --recursive llm-reasoners_tutorial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2wOfzuD1dyn",
        "outputId": "8d6694cb-92e0-4880-d413-4174709a4893"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm-reasoners_tutorial'...\n",
            "remote: Enumerating objects: 4085, done.\u001b[K\n",
            "remote: Counting objects: 100% (2766/2766), done.\u001b[K\n",
            "remote: Compressing objects: 100% (960/960), done.\u001b[K\n",
            "remote: Total 4085 (delta 1912), reused 2561 (delta 1789), pack-reused 1319\u001b[K\n",
            "Receiving objects: 100% (4085/4085), 16.31 MiB | 10.03 MiB/s, done.\n",
            "Resolving deltas: 100% (2731/2731), done.\n",
            "Submodule 'exllama' (https://github.com/turboderp/exllama.git) registered for path 'exllama'\n",
            "Cloning into '/content/llm-reasoners_tutorial/exllama'...\n",
            "remote: Enumerating objects: 1523, done.        \n",
            "remote: Counting objects: 100% (860/860), done.        \n",
            "remote: Compressing objects: 100% (290/290), done.        \n",
            "remote: Total 1523 (delta 686), reused 604 (delta 569), pack-reused 663        \n",
            "Receiving objects: 100% (1523/1523), 949.94 KiB | 18.27 MiB/s, done.\n",
            "Resolving deltas: 100% (1063/1063), done.\n",
            "Submodule path 'exllama': checked out '74e0ddd69fde8b7887552e6c23b88c418cf7e713'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj-ANovHTVhD",
        "outputId": "1c3f33c1-dde0-43bc-d85c-c6846c7b67c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llm-reasoners_tutorial\n"
          ]
        }
      ],
      "source": [
        "%cd llm-reasoners_tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl0JAZvGTjB2",
        "outputId": "99d15268-245b-43b9-eab3-8285523967a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/llm-reasoners_tutorial\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llama1@ git+https://github.com/AegeanYan/llama@llama_v1 (from reasoners==0.0.0)\n",
            "  Cloning https://github.com/AegeanYan/llama (to revision llama_v1) to /tmp/pip-install-znlj40nh/llama1_74ce7d1e2c5947a18f1221582b48e686\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AegeanYan/llama /tmp/pip-install-znlj40nh/llama1_74ce7d1e2c5947a18f1221582b48e686\n",
            "  Running command git checkout -b llama_v1 --track origin/llama_v1\n",
            "  Switched to a new branch 'llama_v1'\n",
            "  Branch 'llama_v1' set up to track remote branch 'llama_v1' from 'origin'.\n",
            "  Resolved https://github.com/AegeanYan/llama to commit bbb5c8e861e25e073bc4d3356152b1ac8422aa09\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llama@ git+https://github.com/facebookresearch/llama@main (from reasoners==0.0.0)\n",
            "  Cloning https://github.com/facebookresearch/llama (to revision main) to /tmp/pip-install-znlj40nh/llama_71f593dbd4c04d95ad812048e3411643\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/llama /tmp/pip-install-znlj40nh/llama_71f593dbd4c04d95ad812048e3411643\n",
            "  Resolved https://github.com/facebookresearch/llama to commit ef351e9cd9496c579bf9f2bb036ef11bdc5ca3d2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from reasoners==0.0.0) (4.66.1)\n",
            "Collecting fire (from reasoners==0.0.0)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from reasoners==0.0.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from reasoners==0.0.0) (1.11.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from reasoners==0.0.0) (2.1.0+cu121)\n",
            "Collecting datasets (from reasoners==0.0.0)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from reasoners==0.0.0) (0.20.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from reasoners==0.0.0) (4.35.2)\n",
            "Collecting sentencepiece (from reasoners==0.0.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai (from reasoners==0.0.0)\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tarski (from reasoners==0.0.0)\n",
            "  Downloading tarski-0.8.2-py3-none-any.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft (from reasoners==0.0.0)\n",
            "  Downloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum (from reasoners==0.0.0)\n",
            "  Downloading optimum-1.16.1-py3-none-any.whl (403 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.3/403.3 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from reasoners==0.0.0)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from reasoners==0.0.0)\n",
            "  Downloading bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale (from reasoners==0.0.0)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets->reasoners==0.0.0)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->reasoners==0.0.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (3.4.1)\n",
            "Collecting multiprocess (from datasets->reasoners==0.0.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (3.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->reasoners==0.0.0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->reasoners==0.0.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->reasoners==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->reasoners==0.0.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->reasoners==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->reasoners==0.0.0) (2.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->reasoners==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->reasoners==0.0.0) (2.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->reasoners==0.0.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->reasoners==0.0.0) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai->reasoners==0.0.0)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->reasoners==0.0.0) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->reasoners==0.0.0) (1.3.0)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub->reasoners==0.0.0)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting coloredlogs (from optimum->reasoners==0.0.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft->reasoners==0.0.0) (5.9.5)\n",
            "Collecting accelerate>=0.21.0 (from peft->reasoners==0.0.0)\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft->reasoners==0.0.0) (0.4.1)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from tarski->reasoners==0.0.0) (1.0.0)\n",
            "Collecting antlr4-python3-runtime==4.7.2 (from tarski->reasoners==0.0.0)\n",
            "  Downloading antlr4-python3-runtime-4.7.2.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->reasoners==0.0.0) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->reasoners==0.0.0) (0.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->reasoners==0.0.0) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->reasoners==0.0.0) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->reasoners==0.0.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->reasoners==0.0.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->reasoners==0.0.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->reasoners==0.0.0) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->reasoners==0.0.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->reasoners==0.0.0) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->reasoners==0.0.0) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->reasoners==0.0.0)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->reasoners==0.0.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->reasoners==0.0.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->reasoners==0.0.0) (2.0.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers->reasoners==0.0.0) (3.20.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum->reasoners==0.0.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->reasoners==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->reasoners==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->reasoners==0.0.0) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->reasoners==0.0.0) (1.3.0)\n",
            "Building wheels for collected packages: fairscale, fire, llama, llama1, antlr4-python3-runtime\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332104 sha256=6b04ea160815d70ae09cfc4a2ee99389e17b83a9ba0d070d307dd0d8bac08639\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=49f1d9c3629e646306f31627a318f6d67a95003cc720b05f6747bdc6414401f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for llama (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama: filename=llama-0.0.1-py3-none-any.whl size=14380 sha256=a5fb8d8b6116b33896a95d052e02fabeaf2913fae042002ca5e07967ac159987\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lpvv0t2q/wheels/45/12/a6/4b0afb0097259ac4aa71be3eaf224bead3a32c3ac64fa61af7\n",
            "  Building wheel for llama1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama1: filename=llama1-0.0.0-py3-none-any.whl size=17887 sha256=7e5d62a74c64492e0b061d46922ccad1ad6e8df25ac54bedd88245d6f66102b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lpvv0t2q/wheels/c8/44/d8/8e82fa63fbc38bbbbb9be3d6e2c514b67914e0ff635af71aee\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.7.2-py3-none-any.whl size=140930 sha256=9cd5d0f266ec7c3db999f9c21c602645eaac611d797fd953864a8d66288e2c52\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/20/ec/30bf7dabc29319ccc0d0c96f910a640513a3c81faa960fed43\n",
            "Successfully built fairscale fire llama llama1 antlr4-python3-runtime\n",
            "Installing collected packages: sentencepiece, ninja, llama1, bitsandbytes, antlr4-python3-runtime, typing-extensions, tarski, pyarrow-hotfix, humanfriendly, h11, fire, dill, multiprocess, httpcore, coloredlogs, httpx, fairscale, accelerate, openai, llama, datasets, peft, optimum, reasoners\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Running setup.py develop for reasoners\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.25.0 antlr4-python3-runtime-4.7.2 bitsandbytes-0.41.3.post2 coloredlogs-15.0.1 datasets-2.16.1 dill-0.3.7 fairscale-0.4.13 fire-0.5.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 humanfriendly-10.0 llama-0.0.1 llama1-0.0.0 multiprocess-0.70.15 ninja-1.11.1.1 openai-1.6.1 optimum-1.16.1 peft-0.7.1 pyarrow-hotfix-0.6 reasoners sentencepiece-0.1.99 tarski-0.8.2 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s1Qoqb9tCJro",
        "outputId": "abc0fc17-1826-459a-fc7a-6ff3321eea7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/llama@llama_v1 (from -r requirements.txt (line 11))\n",
            "  Cloning https://github.com/facebookresearch/llama (to revision llama_v1) to /tmp/pip-req-build-p757aphp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/llama /tmp/pip-req-build-p757aphp\n",
            "  Running command git checkout -b llama_v1 --track origin/llama_v1\n",
            "  Switched to a new branch 'llama_v1'\n",
            "  Branch 'llama_v1' set up to track remote branch 'llama_v1' from 'origin'.\n",
            "  Resolved https://github.com/facebookresearch/llama to commit 57b0eb62de0636e75af471e49e2f1862d908d9d8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.0+cu121)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.16.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.35.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.1.99)\n",
            "Requirement already satisfied: fairscale in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.4.13)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.6.1)\n",
            "Requirement already satisfied: requests~=2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.31.0)\n",
            "Requirement already satisfied: PyYAML~=6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (6.0.1)\n",
            "Requirement already satisfied: tarski~=0.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.8.2)\n",
            "Collecting setuptools~=67.8.0 (from -r requirements.txt (line 19))\n",
            "  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft~=0.5.0 (from -r requirements.txt (line 23))\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (1.16.1)\n",
            "Requirement already satisfied: ninja~=1.11.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (1.11.1.1)\n",
            "Requirement already satisfied: bitsandbytes~=0.41.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (0.41.3.post2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (0.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 14)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->-r requirements.txt (line 14)) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 14)) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 14)) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->-r requirements.txt (line 14)) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.31.0->-r requirements.txt (line 16)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.31.0->-r requirements.txt (line 16)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.31.0->-r requirements.txt (line 16)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.31.0->-r requirements.txt (line 16)) (2023.11.17)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from tarski~=0.8.2->-r requirements.txt (line 18)) (1.0.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.7.2 in /usr/local/lib/python3.10/dist-packages (from tarski~=0.8.2->-r requirements.txt (line 18)) (4.7.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tarski~=0.8.2->-r requirements.txt (line 18)) (5.9.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft~=0.5.0->-r requirements.txt (line 23)) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum->-r requirements.txt (line 24)) (15.0.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 14)) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 14)) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 14)) (0.14.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum->-r requirements.txt (line 24)) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 6)) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: llama\n",
            "  Building wheel for llama (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama: filename=llama-0.0.0-py3-none-any.whl size=17862 sha256=1785d396370acb13f964a730e070630d9c7128078bc691ee8b640521cfd63d54\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d3oixaoz/wheels/2b/52/58/73f1ca5bfa254c328b923c8955c028e4403180909cb232e560\n",
            "Successfully built llama\n",
            "Installing collected packages: llama, setuptools, peft\n",
            "  Attempting uninstall: llama\n",
            "    Found existing installation: llama 0.0.1\n",
            "    Uninstalling llama-0.0.1:\n",
            "      Successfully uninstalled llama-0.0.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.7.1\n",
            "    Uninstalling peft-0.7.1:\n",
            "      Successfully uninstalled peft-0.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llama-0.0.0 peft-0.5.0 setuptools-67.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x9TErecD_Pm"
      },
      "source": [
        "/content/llm-reasoners_tutorial/reasoners/lm/hf_model.py の98行目をコメントアウトする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AaOu1Or7EZZf",
        "outputId": "e0432ceb-e84e-4c65-c157-98d72d7a0f71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!pip install -q huggingface_hub\n",
        "import huggingface_hub\n",
        "huggingface_hub.login(token=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfF1fWLz2H9c",
        "outputId": "919ba6da-aa4d-4c69-8345-4e94e72749b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karthikv792/LLMs-Planning.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maTrB6nc2MVF",
        "outputId": "a3e2b6d6-8391-432d-da88-08a690606119"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLMs-Planning'...\n",
            "remote: Enumerating objects: 7273, done.\u001b[K\n",
            "remote: Counting objects: 100% (1226/1226), done.\u001b[K\n",
            "remote: Compressing objects: 100% (259/259), done.\u001b[K\n",
            "remote: Total 7273 (delta 1077), reused 1060 (delta 965), pack-reused 6047\u001b[K\n",
            "Receiving objects: 100% (7273/7273), 31.20 MiB | 15.08 MiB/s, done.\n",
            "Resolving deltas: 100% (4449/4449), done.\n",
            "Updating files: 100% (8893/8893), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/llm-reasoners_tutorial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b08xXye3FFm",
        "outputId": "beaf6d08-eb1a-48a4-b2f7-3402bb714e64"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llm-reasoners_tutorial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_path(path):\n",
        "    split_path = path.split(\"/\")\n",
        "    new_path = \"/content/LLMs-Planning/llm_planning_analysis/instances/blocksworld/\" + split_path[-2] + \"/\" + split_path[-1]\n",
        "    return new_path"
      ],
      "metadata": {
        "id": "XdNejCBstwWb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: jsonファイルを読み込み，一行ずつ書き換える\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/content/llm-reasoners_tutorial/examples/rap_blocksworld/data/step_2.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for i in range(len(data)):\n",
        "    data[i][0] = correct_path(data[i][0])\n",
        "\n",
        "with open('/content/llm-reasoners_tutorial/examples/rap_blocksworld/data/step_2.json', 'w') as f:\n",
        "    json.dump(data, f)\n"
      ],
      "metadata": {
        "id": "E6pZoWHrC7mF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FarIKkN6U6ka",
        "outputId": "97323ee4-1b7e-4682-818d-a280eaa7c10f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-07 07:30:58.298230: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-07 07:30:58.298294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-07 07:30:58.299681: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-07 07:30:59.427623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "quantizing.............................\n",
            "Loading checkpoint shards: 100% 2/2 [01:08<00:00, 34.02s/it]\n",
            "Blocksworld:   0% 0/30 [00:00<?, ?it/s]/content/llm-reasoners_tutorial/reasoners/lm/hf_model.py:137: UserWarning: the eos_token '\\n' is encoded into [29871, 13] with length != 1, using 13 as the eos_token_id\n",
            "  warnings.warn(f'the eos_token {repr(token)} is encoded into {tokenized} with length != 1, '\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "[+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #1: correct=False; accuracy=0.000 (0/1)\n",
            "Blocksworld:   3% 1/30 [01:04<31:20, 64.83s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #2: correct=False; accuracy=0.000 (0/2)\n",
            "Blocksworld:   7% 2/30 [02:08<29:58, 64.23s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #3: correct=False; accuracy=0.000 (0/3)\n",
            "Blocksworld:  10% 3/30 [03:25<31:33, 70.12s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #4: correct=False; accuracy=0.000 (0/4)\n",
            "Blocksworld:  13% 4/30 [06:39<51:27, 118.75s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #5: correct=False; accuracy=0.000 (0/5)\n",
            "Blocksworld:  17% 5/30 [07:55<43:07, 103.51s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #6: correct=False; accuracy=0.000 (0/6)\n",
            "Blocksworld:  20% 6/30 [09:11<37:40, 94.20s/it] [+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #7: correct=False; accuracy=0.000 (0/7)\n",
            "Blocksworld:  23% 7/30 [12:00<45:24, 118.45s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #8: correct=False; accuracy=0.000 (0/8)\n",
            "Blocksworld:  27% 8/30 [13:27<39:49, 108.61s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #9: correct=False; accuracy=0.000 (0/9)\n",
            "Blocksworld:  30% 9/30 [17:31<52:46, 150.80s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #10: correct=False; accuracy=0.000 (0/10)\n",
            "Blocksworld:  33% 10/30 [20:18<51:56, 155.80s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #11: correct=False; accuracy=0.000 (0/11)\n",
            "Blocksworld:  37% 11/30 [23:37<53:34, 169.18s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #12: correct=False; accuracy=0.000 (0/12)\n",
            "Blocksworld:  40% 12/30 [24:42<41:12, 137.35s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #13: correct=False; accuracy=0.000 (0/13)\n",
            "Blocksworld:  43% 13/30 [31:04<59:58, 211.67s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #14: correct=False; accuracy=0.000 (0/14)\n",
            "Blocksworld:  47% 14/30 [34:19<55:02, 206.39s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #15: correct=False; accuracy=0.000 (0/15)\n",
            "Blocksworld:  50% 15/30 [38:16<53:55, 215.70s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #16: correct=False; accuracy=0.000 (0/16)\n",
            "Blocksworld:  53% 16/30 [39:42<41:15, 176.83s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #17: correct=False; accuracy=0.000 (0/17)\n",
            "Blocksworld:  57% 17/30 [40:59<31:48, 146.78s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #18: correct=False; accuracy=0.000 (0/18)\n",
            "Blocksworld:  60% 18/30 [47:22<43:31, 217.61s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #19: correct=False; accuracy=0.000 (0/19)\n",
            "Blocksworld:  63% 19/30 [48:25<31:23, 171.19s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #20: correct=False; accuracy=0.000 (0/20)\n",
            "Blocksworld:  67% 20/30 [49:29<23:09, 138.91s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #21: correct=False; accuracy=0.000 (0/21)\n",
            "Blocksworld:  70% 21/30 [52:42<23:17, 155.29s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #22: correct=False; accuracy=0.000 (0/22)\n",
            "Blocksworld:  73% 22/30 [55:29<21:10, 158.75s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #23: correct=False; accuracy=0.000 (0/23)\n",
            "Blocksworld:  77% 23/30 [56:55<15:59, 137.07s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #24: correct=False; accuracy=0.000 (0/24)\n",
            "Blocksworld:  80% 24/30 [1:00:20<15:43, 157.31s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #25: correct=False; accuracy=0.000 (0/25)\n",
            "Blocksworld:  83% 25/30 [1:01:36<11:05, 133.01s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #26: correct=False; accuracy=0.000 (0/26)\n",
            "Blocksworld:  87% 26/30 [1:03:16<08:12, 123.13s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #27: correct=False; accuracy=0.000 (0/27)\n",
            "Blocksworld:  90% 27/30 [1:06:43<07:24, 148.29s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #28: correct=False; accuracy=0.000 (0/28)\n",
            "Blocksworld:  93% 28/30 [1:09:58<05:24, 162.19s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #29: correct=False; accuracy=0.000 (0/29)\n",
            "Blocksworld:  97% 29/30 [1:11:14<02:16, 136.36s/it][+]: Saving plan in lm_plan.tmp\n",
            "/bin/sh: 1: None/validate: not found\n",
            "RESPONSE::: \n",
            "Case #30: correct=False; accuracy=0.000 (0/30)\n",
            "Blocksworld: 100% 30/30 [1:14:29<00:00, 148.97s/it]\n"
          ]
        }
      ],
      "source": [
        "# assets/llm-reasoners_tutorial/examples/rap_blocksworld/inference.pyの235行目をfire.Fire(llama_hf_main)に変更\n",
        "\n",
        "!python examples/rap_blocksworld/inference.py --data_path 'examples/rap_blocksworld/data/step_2.json' --depth_limit 4 --llama_path \"meta-llama/Llama-2-7b-hf\" --peft_path None --batch_size 1 --quantized 'nf4' --output_trace_in_each_iter\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}